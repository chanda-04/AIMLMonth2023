{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmjhRLtszi07l0XXyz28JC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chanda-04/AIMLMonth2023/blob/main/Major_Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exoplanet Detection and Classification using Machine Learning**"
      ],
      "metadata": {
        "id": "rjcnPcizBJCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "**Exoplanet Detection**:\n",
        "\n",
        "Exoplanet detection involves identifying the presence of planets orbiting stars based on various observable signals, such as changes in brightness (transits) or radial velocity variations. Machine learning can enhance the efficiency and accuracy of detecting exoplanets in large datasets.\n",
        "\n",
        "**The Transit Method of Detecting Extrasolar Planets**\n",
        "\n",
        "When a planet passes in front of a star as viewed from Earth, the event is called a “transit”. On Earth, we can observe an occasional Venus or Mercury transit. These events are seen as a small black dot creeping across the Sun—Venus or Mercury blocks sunlight as the planet moves between the Sun and us. Kepler finds planets by looking for tiny dips in the brightness of a star when a planet crosses in front of it—we say the planet transits the star.\n",
        "\n",
        "Once detected, the planet's orbital size can be calculated from the period (how long it takes the planet to orbit once around the star) and the mass of the star using Kepler's Third Law of planetary motion. The size of the planet is found from the depth of the transit (how much the brightness of the star drops) and the size of the star. From the orbital size and the temperature of the star, the planet's characteristic temperature can be calculated. From this the question of whether or not the planet is habitable (not necessarily inhabited) can be answered."
      ],
      "metadata": {
        "id": "5_md75PLCuWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem statement**\n",
        "ML algorithms can be trained to identify transit-like patterns in light curves. These algorithms learn to differentiate between actual transits and noise, helping to detect exoplanet candidates more effectively."
      ],
      "metadata": {
        "id": "iLk5rGF0C_tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**about the Dataset:**  \n",
        "\n",
        "The data describe the change in flux (light intensity) of several thousand stars. Each star has a binary label of 2 or 1. 2 indicated that that the star is confirmed to have at least one exoplanet in orbit; some observations are in fact multi-planet systems.\n",
        "\n",
        "As you can imagine, planets themselves do not emit light, but the stars that they orbit do. If said star is watched over several months or years, there may be a regular 'dimming' of the flux (the light intensity). This is evidence that there may be an orbiting body around the star; such a star could be considered to be a 'candidate' system. Further study of our candidate system, for example by a satellite that captures light at a different wavelength, could solidify the belief that the candidate can in fact be 'confirmed'.\n",
        "\n",
        "link: https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data?resource=download&select=exoTrain.csv"
      ],
      "metadata": {
        "id": "EYtBTnxpDD-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "zao5fyTbDSQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the idea about dataset\n",
        "train_data = pd.read_csv('/exoTrain.csv.zip')\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "v_fZqwaPDawu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of dataset\n",
        "train_data.shape"
      ],
      "metadata": {
        "id": "iyYXVr67DdnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has 5087 stars. For each star we have 3187 flux values at different time intervals.\n",
        "\n",
        "As this dataset has data containing data based on transit method for detecting exoplanets, these flux values will be used to detect if a star has exoplanest(s)"
      ],
      "metadata": {
        "id": "etSJKwPzDiTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for rows with null values and displaying them\n",
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "id": "77zuOmsqDpYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(train_data.isnull())"
      ],
      "metadata": {
        "id": "0mSxhH3eDuqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are no missing values"
      ],
      "metadata": {
        "id": "0EWKjs8_D1ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking how many labels are present in the dataset\n",
        "train_data['LABEL'].unique()"
      ],
      "metadata": {
        "id": "52UgyiiYD0ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hence there are 2 labels:\n",
        "1.   for star not containing exoplanets\n",
        "2.   for star containing exoplanets"
      ],
      "metadata": {
        "id": "UaPf_NWfD7_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the label values\n",
        "train_data = train_data.replace({'LABEL' : {1:0, 2:1}})\n",
        "train_data['LABEL'].unique()\n",
        "\n"
      ],
      "metadata": {
        "id": "sPzt5iAsEVAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have replaced the values from 2,1 to 1,0 respectively as its much better to use values 0,1 for classification"
      ],
      "metadata": {
        "id": "s6gOqwFkEait"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"no. of stars with exoplanets=\",len(train_data[train_data['LABEL']==1]))\n",
        "print(\"no. of stars without exoplanets=\",len(train_data[train_data['LABEL']==0]))\n",
        "#plotting a countplot\n",
        "column_name = 'LABEL'\n",
        "plt.figure(figsize=(3, 10))\n",
        "\n",
        "sns.countplot(data=train_data, x=column_name)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(column_name)\n",
        "plt.ylabel('Count')\n",
        "plt.title(f'Countplot of {column_name}')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8rgDvqlEEecY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Visualising the light curves in this data**\n",
        "\n",
        "When a planet passes between an observer and the star, the flux value decreases and hence we see a dip in light curves with exoplanets\n"
      ],
      "metadata": {
        "id": "HZqM0j0BEyKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the label column as we dont need it for plotting the light curve\n",
        "plot_train=train_data.drop([\"LABEL\"],axis=1)\n",
        "plot_train"
      ],
      "metadata": {
        "id": "GUjY77BuE1GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting a star with confirmed exoplanets i.e. having label as 1 to visualize how the light curve of a star with exoplanet looks like\n",
        "x=range(1,3198)\n",
        "y=plot_train.iloc[16,:].values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x,y,linewidth=0.5)"
      ],
      "metadata": {
        "id": "dBeTwGMaE7SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the dips in the above graphs represents the dimming of the flux (the light intensity). This is evidence that there may be an orbiting body i.e. exoplanet around the star. this type of graph with dips in flux is common with all the stars who are confirmed canditates"
      ],
      "metadata": {
        "id": "qL18msrVFByT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting a star with no exoplanets i.e. having label as 0 to visualize how the light curve of a star without exoplanet looks like\n",
        "x=range(1,3198)\n",
        "y=plot_train.iloc[40,:].values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x,y,linewidth=2)"
      ],
      "metadata": {
        "id": "Y09KSFfHFFpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are no dips in the above graphs representing the dimming of the flux (the light intensity).This graph is 'flatter' compared to the previous group. This is evidence that there is no orbiting body i.e. exoplanet around the star which will cause the dimming of the flux."
      ],
      "metadata": {
        "id": "zZ8GZ4aKFKVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the scenario where you want to predict whether a star has exoplanets or not based on flux values, it would be more appropriate to use classification rather than regression."
      ],
      "metadata": {
        "id": "sYO-DIjnFPTU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuYpH6t7FXrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing**"
      ],
      "metadata": {
        "id": "z2YV-yn8FYbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting independent (x) and dependent (y) features from our dataset\n",
        "x=train_data.drop([\"LABEL\"], axis=1)\n",
        "y=train_data.LABEL"
      ],
      "metadata": {
        "id": "ThvwAAnZFbZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling the imbalance in the data:**\n",
        "\n",
        "our dataset is imbalanced, where one class(label=0) has significantly more samples than the others, the classifier can be biased towards the majority class."
      ],
      "metadata": {
        "id": "wvdbQjPfFfXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Over-Sampling technique focuses on the minority class (the class with fewer samples) and aims to balance the class distribution by randomly duplicating instances from the minority class until its size matches the size of the majority class.\n",
        "\n",
        "Random Over-Sampling process works:\n",
        "\n",
        "    Identify the minority class that you want to balance.\n",
        "\n",
        "    Randomly select instances from the minority class with replacement (allowing the same instance to be selected multiple times), adding these instances to the dataset.\n",
        "\n",
        "    Repeat step 2 until the size of the minority class reaches the desired level of balance or matches the size of the majority class.\n",
        "\n",
        "    Use the balanced dataset for training your machine learning model."
      ],
      "metadata": {
        "id": "tSHZz7_LFo6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "ros = RandomOverSampler()\n",
        "x_ros, y_ros = ros.fit_resample(x, y)\n",
        "print(f\"Before sampling:- {Counter(y)}\")\n",
        "print(f\"After sampling:- {Counter(y_ros)}\")\n"
      ],
      "metadata": {
        "id": "rI9TcwIZFwGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing\n",
        "y_ros.value_counts().plot(kind='bar', title='After aplying RandomOverSampler')"
      ],
      "metadata": {
        "id": "AOf_1EmnF4r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting this data (70:30) into train and test data for our model development"
      ],
      "metadata": {
        "id": "0DnibkwlF9YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, test_size = 0.3, random_state = 0)\n"
      ],
      "metadata": {
        "id": "Jz-XW5EUGEFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling to ensure all features are on a similar scale."
      ],
      "metadata": {
        "id": "60ua-gp2GH5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_sc = sc.fit_transform(X_train)\n",
        "X_test_sc = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "-dIe7OVDGL0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model selection**"
      ],
      "metadata": {
        "id": "n3hhS5OSGPRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this project we are going to demonstrate 3 machine learning classification methods:\n",
        "\n",
        "1.   K-Nearest Neighbors (KNN)\n",
        "2.   Random forest classifier\n",
        "3.   decision tree classifier\n",
        "\n",
        "find which one gives the best results.\n",
        "\n"
      ],
      "metadata": {
        "id": "ypLPbfu7GS-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Nearest Neighbors (KNN)**"
      ],
      "metadata": {
        "id": "AKDrnx72GWra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train the K-Nearest Neighbors (KNN) model:**\n",
        "\n",
        "1.   Import the KNeighborsClassifier class from scikit-learn.\n",
        "2.   Create an instance of the K-Nearest Neighbors (KNN) and fit it to the training data.\n",
        "3.   Use the fit method to train the model.  "
      ],
      "metadata": {
        "id": "k-LMPgg-GZdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNC"
      ],
      "metadata": {
        "id": "Fgp0esR8GcmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing K = 1\n",
        "knn_classifier = KNC(n_neighbors=1,metric='minkowski',p=2)\n",
        "#metric is to be by default minkowski for p = 2 to calculate the Eucledian distances\n",
        "# Fit the model\n",
        "knn_classifier.fit(X_train_sc, y_train)\n"
      ],
      "metadata": {
        "id": "dbj6FSn5Gfk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Predictions**\n",
        "    \n",
        "1. Use the trained knn classifier to make predictions on the testing data.\n",
        "2. Use the predict method to obtain the predicted labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "LktvUby6GjJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_pred_knn = knn_classifier.predict(X_test_sc)"
      ],
      "metadata": {
        "id": "mxurJzcIGluq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**\n",
        "1.   Assess the performance of the knn model using evaluation metrics such as accuracy, precision, recall, and F1 score.\n",
        "2.   Compare the predicted labels (y_pred) with the actual labels (y_test).\n",
        "\n"
      ],
      "metadata": {
        "id": "oUskmbHLGoJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print('Validation accuracy of KNN is', accuracy_score(y_test,y_pred_knn))\n",
        "print (\"\\nClassification report :\\n\",(classification_report(y_test,y_pred_knn)))\n",
        "\n",
        "#Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_knn)\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
        "            yticklabels=[\"Actual Negative\", \"Actual Positive\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rZ6a7_WwGqNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random forest classifier**"
      ],
      "metadata": {
        "id": "pDO0IsewGuju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train the Random forest classifier model:**\n",
        "\n",
        "1.   Import the RandomForestClassifier class from scikit-ensemble.\n",
        "2.   Create an instance of the Random forest classifier and fit it to the training data.\n",
        "3.   Use the fit method to train the model.  "
      ],
      "metadata": {
        "id": "KZNpu3SyGxK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(n_estimators=100, criterion='gini')\n",
        "forest.fit(X_train_sc, y_train)"
      ],
      "metadata": {
        "id": "hL9HiQhPG0Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Predictions**\n",
        "    \n",
        "1. Use the trained Random forest classifier to make predictions on the testing data.\n",
        "2. Use the predict method to obtain the predicted labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "6umZ1FhCG3tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set\n",
        "y_pred_rf = forest.predict(X_test_sc)"
      ],
      "metadata": {
        "id": "_RjsskfvG8ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**\n",
        "1.   Assess the performance of the Random forest  model using evaluation metrics such as accuracy, precision, recall, and F1 score.\n",
        "2.   Compare the predicted labels (y_pred) with the actual labels (y_test).\n",
        "\n"
      ],
      "metadata": {
        "id": "x3nrO1fHHDxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print('\\nValidation accuracy of RandomForestClassifier  is', accuracy_score(y_test,y_pred_rf))\n",
        "print (\"\\nClassification report :\\n\",(classification_report(y_test,y_pred_rf)))\n",
        "\n",
        "#Confusion matrix\n",
        "#Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
        "            yticklabels=[\"Actual Negative\", \"Actual Positive\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Swox4AKuHHmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **decision tree classifier**"
      ],
      "metadata": {
        "id": "FNjS1RNdHK55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train the decision tree classifier model:**\n",
        "\n",
        "1.   Import the RandomForestClassifier class from scikit-ensemble.\n",
        "2.   Create an instance of the decision tree classifier and fit it to the training data.\n",
        "3.   Use the fit method to train the model.  "
      ],
      "metadata": {
        "id": "MsPSgmV5HNde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train_sc, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "M_4sxBUhHP-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Predictions**\n",
        "    \n",
        "1. Use the trained decision tree classifier to make predictions on the testing data.\n",
        "2. Use the predict method to obtain the predicted labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "lKNZ5p3EHUBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dt = dt_classifier.predict(X_test_sc)"
      ],
      "metadata": {
        "id": "C_7ydbahHWsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**\n",
        "1.   Assess the performance of the decision tree classifier model using evaluation metrics such as accuracy, precision, recall, and F1 score.\n",
        "2.   Compare the predicted labels (y_pred) with the actual labels (y_test).\n",
        "\n"
      ],
      "metadata": {
        "id": "c2GsgbNfHZSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print('\\nValidation accuracy of DecisionTreeClassifier  is', accuracy_score(y_test,y_pred_dt))\n",
        "print (\"\\nClassification report :\\n\",(classification_report(y_test,y_pred_dt)))\n",
        "\n",
        "#Confusion matrix\n",
        "#Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_dt)\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
        "            yticklabels=[\"Actual Negative\", \"Actual Positive\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gQ1b2PlWHbld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNbFlLxHHf1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Future Scope**"
      ],
      "metadata": {
        "id": "tqd0uaOCHh2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to note that while machine learning offers powerful tools for exoplanet detection and classification, it also presents challenges related to dataset quality, overfitting, and model interpretability. Collaborations between astrophysicists, data scientists, and machine learning experts are crucial for developing robust and reliable models for exoplanet research. As the field continues to evolve, machine learning will likely play an increasingly integral role in our understanding of exoplanetary systems."
      ],
      "metadata": {
        "id": "GockArHNHlNK"
      }
    }
  ]
}